import React, { useState, useRef, useEffect } from 'react';
import {
  Bot, Send, X, Settings, Trash2, Plus, Edit3
} from 'lucide-react';
import AIMessage, { type AIMessageData } from './AIMessage';
import QuickActions from './QuickActions';

// é¢„ç½®ç³»ç»ŸPromptæ¨¡æ¿
const PRESET_SYSTEM_PROMPTS = {
  novelist: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº’åŠ¨å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ›ä½œç²¾å½©çš„AVGæ¸¸æˆå‰§æœ¬ã€‚ä½ çš„ä»»åŠ¡åŒ…æ‹¬ï¼š
1. å¸®åŠ©è®¾è®¡æœ‰æ·±åº¦çš„è§’è‰²å’Œä¸–ç•Œè§‚
2. æ„æ€å¼•äººå…¥èƒœçš„å‰§æƒ…å’Œåˆ†æ”¯
3. ç¼–å†™è‡ªç„¶ç”ŸåŠ¨çš„å¯¹è¯
4. æä¾›åˆ›ä½œå»ºè®®å’Œçµæ„Ÿ
5. ååŠ©ä¼˜åŒ–æ•…äº‹ç»“æ„å’ŒèŠ‚å¥

è¯·ä»¥å¯Œæœ‰åˆ›é€ åŠ›å’Œä¸“ä¸šæ€§çš„æ–¹å¼æä¾›å¸®åŠ©ï¼Œä½¿ç”¨ä¸­æ–‡å›å¤ã€‚`,
  
  coder: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Inkè„šæœ¬è¯­è¨€ç¼–ç¨‹åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç¼–å†™å’Œä¼˜åŒ–äº’åŠ¨å°è¯´çš„è„šæœ¬ä»£ç ã€‚ä½ çš„ä»»åŠ¡åŒ…æ‹¬ï¼š
1. è§£é‡ŠInkè¯­æ³•å’Œä½¿ç”¨æ–¹æ³•
2. å¸®åŠ©ä¿®å¤è¯­æ³•é”™è¯¯å’Œé€»è¾‘é—®é¢˜
3. ä¼˜åŒ–ä»£ç ç»“æ„å’Œå¯è¯»æ€§
4. æä¾›æœ€ä½³å®è·µå»ºè®®
5. ç”Ÿæˆç¬¦åˆè§„èŒƒçš„Inkä»£ç 

è¯·æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„æŠ€æœ¯æŒ‡å¯¼ï¼Œä»£ç ç¤ºä¾‹è¯·ä½¿ç”¨Inkè¯­æ³•æ ¼å¼ã€‚`,
  
  analyzer: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¸¸æˆå‰§æƒ…åˆ†æå¸ˆï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ†æå’Œæ”¹è¿›äº’åŠ¨å°è¯´ã€‚ä½ çš„ä»»åŠ¡åŒ…æ‹¬ï¼š
1. åˆ†æå‰§æƒ…ç»“æ„å’Œé€»è¾‘
2. è¯„ä¼°è§’è‰²å‘å±•å’ŒåŠ¨æœº
3. æ£€æŸ¥åˆ†æ”¯é€‰é¡¹çš„å¹³è¡¡æ€§
4. æä¾›æ”¹è¿›å»ºè®®
5. è¯†åˆ«æ½œåœ¨é—®é¢˜å’Œé£é™©

è¯·ä»¥å®¢è§‚ã€ä¸“ä¸šçš„è§’åº¦æä¾›åˆ†æï¼Œç»™å‡ºå…·ä½“å¯è¡Œçš„å»ºè®®ã€‚`,
  
  teacher: `ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„äº’åŠ¨å°è¯´åˆ›ä½œå¯¼å¸ˆï¼Œä¸“é—¨å¸®åŠ©åˆå­¦è€…å­¦ä¹ AVGæ¸¸æˆåˆ›ä½œã€‚ä½ çš„ä»»åŠ¡åŒ…æ‹¬ï¼š
1. ç”¨ç®€å•æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šæ¦‚å¿µ
2. æä¾›å¾ªåºæ¸è¿›çš„å­¦ä¹ æŒ‡å¯¼
3. è§£ç­”åˆ›ä½œè¿‡ç¨‹ä¸­çš„ç–‘é—®
4. é¼“åŠ±å’Œæ¿€åŠ±åˆ›ä½œè€…
5. åˆ†äº«å®ç”¨çš„åˆ›ä½œæŠ€å·§

è¯·ä¿æŒè€å¿ƒå’Œé¼“åŠ±çš„æ€åº¦ï¼Œä½¿ç”¨æ˜“äºç†è§£çš„è¯­è¨€è¿›è¡ŒæŒ‡å¯¼ã€‚`
};

// AIæ¨¡å‹é…ç½®æ¥å£
interface AIModelConfig {
  id: string;
  name: string;
  provider: 'openai' | 'qwen' | 'anthropic' | 'custom';
  apiUrl: string;
  apiKey: string;
  model: string;
  temperature?: number;
  maxTokens?: number;
  systemPrompt?: string;
  headers?: Record<string, string>;
}

// AIæä¾›å•†é…ç½®
interface AIProviderConfig {
  id: 'openai' | 'qwen' | 'anthropic' | 'custom';
  name: string;
  defaultApiUrl: string;
  apiKeyName: string;
  supportsStreaming: boolean;
}

const SUPPORTED_PROVIDERS: AIProviderConfig[] = [
  {
    id: 'openai',
    name: 'OpenAI',
    defaultApiUrl: 'https://api.openai.com/v1/chat/completions',
    apiKeyName: 'Authorization',
    supportsStreaming: true
  },
  {
    id: 'qwen',
    name: 'é€šä¹‰åƒé—®',
    defaultApiUrl: 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
    apiKeyName: 'Authorization',
    supportsStreaming: true
  },
  {
    id: 'anthropic',
    name: 'Anthropic',
    defaultApiUrl: 'https://api.anthropic.com/v1/messages',
    apiKeyName: 'x-api-key',
    supportsStreaming: true
  },
  {
    id: 'custom',
    name: 'è‡ªå®šä¹‰',
    defaultApiUrl: '',
    apiKeyName: 'Authorization',
    supportsStreaming: false
  }
];

interface AIChatPanelProps {
  isOpen?: boolean;
  onToggle?: () => void;
  projectContext: { currentFile: string | null; projectName?: string | null };
}

export const AIChatPanel: React.FC<AIChatPanelProps> = ({
  isOpen = true,
  onToggle = () => {},
  projectContext,
}) => {
  // ä½¿ç”¨ projectContext æ¥å¢å¼ºAIçš„ä¸Šä¸‹æ–‡ç†è§£
  console.log('ğŸ“ AIChatPanel: å½“å‰é¡¹ç›®ä¸Šä¸‹æ–‡:', projectContext);
  const [messages, setMessages] = useState<AIMessageData[]>([
    {
      id: 1,
      type: 'ai',
      content: 'ä½ å¥½ï¼æˆ‘æ˜¯AVG Makerçš„AIåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®ä½ ï¼š\n\nâ€¢ ç”Ÿæˆå‰§æƒ…å’Œè§’è‰²\nâ€¢ ä¼˜åŒ–Inkä»£ç \nâ€¢ ä¿®å¤è¯­æ³•é”™è¯¯\nâ€¢ æä¾›åˆ›ä½œå»ºè®®\n\nç°åœ¨æƒ³åšä»€ä¹ˆï¼Ÿ',
      timestamp: new Date(),
      actions: ['generate-character', 'create-scene', 'fix-code']
    }
  ]);
  const [input, setInput] = useState('');
  const [isAiThinking, setIsAiThinking] = useState(false);
  const [_suggestions] = useState([
    'å¸®æˆ‘åˆ›å»ºä¸€ä¸ªç¥ç§˜è§’è‰²',
    'ä¼˜åŒ–å½“å‰çš„ä»£ç ç»“æ„',
    'ç”Ÿæˆä¸€ä¸ªè½¬æŠ˜å‰§æƒ…'
  ]);
  // AIæ¨¡å‹é…ç½®ç›¸å…³çŠ¶æ€
  const [models, setModels] = useState<AIModelConfig[]>(() => {
    const savedModels = localStorage.getItem('ai-models');
    return savedModels ? JSON.parse(savedModels) : [];
  });
  const [selectedModelId, setSelectedModelId] = useState<string>(() => {
    return localStorage.getItem('selected-ai-model') || '';
  });
  const [showModelConfig, setShowModelConfig] = useState(false);
  const [editingModel, setEditingModel] = useState<AIModelConfig | null>(null);
  const [tempModelConfig, setTempModelConfig] = useState<AIModelConfig>({
    id: Date.now().toString(),
    name: '',
    provider: 'openai',
    apiUrl: '',
    apiKey: '',
    model: '',
    temperature: 0.7,
    maxTokens: 2048,
    systemPrompt: PRESET_SYSTEM_PROMPTS.novelist
  });
  
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // è·å–å½“å‰é€‰ä¸­çš„æ¨¡å‹é…ç½®
  const getCurrentModel = (): AIModelConfig | undefined => {
    if (!selectedModelId) return undefined;
    return models.find(model => model.id === selectedModelId);
  };

  // æ ¹æ®æä¾›å•†æ„å»ºè¯·æ±‚å¤´
  const buildHeaders = (model: AIModelConfig): Record<string, string> => {
    const provider = SUPPORTED_PROVIDERS.find(p => p.id === model.provider);
    if (!provider) return {};
    
    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
    };
    
    // æ·»åŠ APIå¯†é’¥
    if (model.provider === 'openai') {
      headers[provider.apiKeyName] = `Bearer ${model.apiKey}`;
    } else if (model.provider === 'qwen') {
      headers[provider.apiKeyName] = `Bearer ${model.apiKey}`;
    } else if (model.provider === 'anthropic') {
      headers[provider.apiKeyName] = model.apiKey;
      headers['anthropic-version'] = '2023-06-01';
    } else {
      // è‡ªå®šä¹‰æä¾›å•†
      if (model.headers) {
        Object.assign(headers, model.headers);
      }
      if (model.apiKey && !headers[provider.apiKeyName]) {
        headers[provider.apiKeyName] = model.apiKey;
      }
    }
    
    return headers;
  };

  // æ ¹æ®æä¾›å•†æ„å»ºè¯·æ±‚ä½“
  const buildRequestBody = (model: AIModelConfig, messages: { role: string; content: string }[]): any => {
    // è·å–æ“ä½œç±»å‹ï¼ˆä»æœ€æ–°ç”¨æˆ·æ¶ˆæ¯ä¸­æå–ï¼‰
    const latestUserMessage = messages[messages.length - 1]?.content || '';
    const actionType = Object.keys({
      'generate-character': 'å¸®æˆ‘åˆ›å»ºä¸€ä¸ªæ–°è§’è‰²',
      'create-scene': 'å¸®æˆ‘è®¾è®¡ä¸€ä¸ªæ–°åœºæ™¯',
      'add-dialogue': 'ä¸ºå½“å‰åœºæ™¯ä¸­çš„è§’è‰²ç”Ÿæˆä¸€æ®µè‡ªç„¶çš„å¯¹è¯',
      'plot-twist': 'ä¸ºæˆ‘çš„æ•…äº‹è®¾è®¡ä¸€ä¸ªå‡ºäººæ„æ–™ä½†åˆç†çš„å‰§æƒ…è½¬æŠ˜',
      'fix-syntax': 'æ£€æŸ¥å¹¶ä¿®å¤æˆ‘æä¾›çš„Inkä»£ç ä¸­çš„è¯­æ³•é”™è¯¯',
      'optimize-code': 'ä¼˜åŒ–è¿™æ®µInkä»£ç çš„ç»“æ„å’Œå¯è¯»æ€§',
      'add-variables': 'æ ¹æ®æˆ‘çš„å‰§æƒ…éœ€è¦ï¼Œå»ºè®®ä¸€äº›æœ‰ç”¨çš„å˜é‡æ¥è·Ÿè¸ªçŠ¶æ€',
      'format-code': 'é‡æ–°æ ¼å¼åŒ–è¿™æ®µInkä»£ç ï¼Œä½¿å…¶æ›´æ˜“è¯»',
      'analyze-flow': 'åˆ†ææˆ‘çš„å‰§æƒ…åˆ†æ”¯é€»è¾‘ï¼ŒæŒ‡å‡ºå¯èƒ½çš„é—®é¢˜',
      'check-balance': 'è¯„ä¼°æˆ‘çš„æ¸¸æˆé€‰é¡¹æ˜¯å¦å¹³è¡¡',
      'review-story': 'å…¨é¢è¯„ä¼°æˆ‘çš„æ•…äº‹',
      'suggest-improve': 'åŸºäºå½“å‰å†…å®¹ï¼Œæä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®'
    }).find(key => latestUserMessage.includes(key.split('-')[1])) || '';
    
    // æ ¹æ®æ“ä½œç±»å‹é€‰æ‹©ç³»ç»ŸPromptï¼ˆå¦‚æœæœªè‡ªå®šä¹‰ï¼‰
    let systemPrompt = model.systemPrompt;
    if (systemPrompt === PRESET_SYSTEM_PROMPTS.novelist) {
      if (actionType.includes('fix-syntax') || actionType.includes('optimize-code') || 
          actionType.includes('add-variables') || actionType.includes('format-code')) {
        systemPrompt = PRESET_SYSTEM_PROMPTS.coder;
      } else if (actionType.includes('analyze-flow') || actionType.includes('check-balance') || 
                 actionType.includes('review-story') || actionType.includes('suggest-improve')) {
        systemPrompt = PRESET_SYSTEM_PROMPTS.analyzer;
      }
    }
    
    const commonParams = {
      model: model.model,
      temperature: model.temperature,
      max_tokens: model.maxTokens,
    };
    
    if (model.provider === 'openai') {
      return {
        ...commonParams,
        messages: [
          ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
          ...messages
        ]
      };
    } else if (model.provider === 'qwen') {
      return {
        ...commonParams,
        input: {
          messages: [
            ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
            ...messages
          ]
        },
        parameters: {
          temperature: model.temperature,
          max_tokens: model.maxTokens
        }
      };
    } else if (model.provider === 'anthropic') {
      return {
        model: model.model,
        messages: messages,
        system: systemPrompt,
        max_tokens: model.maxTokens || 1024,
        temperature: model.temperature
      };
    } else {
      // è‡ªå®šä¹‰æä¾›å•†ï¼Œä½¿ç”¨é€šç”¨æ ¼å¼
      return {
        ...commonParams,
        messages: [
          ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
          ...messages
        ]
      };
    }
  };

  // å‘é€æ¶ˆæ¯åˆ°AI API
  const sendToAI = async (userMessage: string) => {
    const currentModel = getCurrentModel();
    if (!currentModel) {
      return 'è¯·å…ˆé…ç½®AIæ¨¡å‹';
    }
    
    try {
      setIsAiThinking(true);
      
      // æ„å»ºæ¶ˆæ¯å†å²
      const historyMessages = messages
        .filter(m => m.type === 'user' || m.type === 'ai')
        .map(m => ({
          role: m.type === 'user' ? 'user' : 'assistant',
          content: m.content
        }));
      
      // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
      historyMessages.push({ role: 'user', content: userMessage });
      
      // æ„å»ºè¯·æ±‚
      const headers = buildHeaders(currentModel);
      const body = buildRequestBody(currentModel, historyMessages);
      
      console.log('å‘é€AIè¯·æ±‚:', { url: currentModel.apiUrl, headers, body });
      
      const response = await fetch(currentModel.apiUrl, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('AI APIé”™è¯¯:', response.status, errorText);
        return `APIé”™è¯¯: ${response.status} - ${errorText}`;
      }
      
      const data = await response.json();
      console.log('AIå“åº”:', data);
      
      // æ ¹æ®ä¸åŒæä¾›å•†è§£æå“åº”
      if (currentModel.provider === 'openai') {
        return data.choices?.[0]?.message?.content || 'æ— å“åº”å†…å®¹';
      } else if (currentModel.provider === 'qwen') {
        return data.output?.text || 'æ— å“åº”å†…å®¹';
      } else if (currentModel.provider === 'anthropic') {
        return data.content?.[0]?.text || 'æ— å“åº”å†…å®¹';
      } else {
        // è‡ªå®šä¹‰æä¾›å•†ï¼Œå°è¯•é€šç”¨è§£æ
        return data.choices?.[0]?.message?.content || 
               data.output?.text || 
               data.content?.[0]?.text || 
               'æ— å“åº”å†…å®¹';
      }
    } catch (error) {
      console.error('AIè¯·æ±‚å¤±è´¥:', error);
      return `è¯·æ±‚å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`;
    } finally {
      setIsAiThinking(false);
    }
  };

  const handleSendMessage = async () => {
    if (!input.trim()) return;

    const userMessage: AIMessageData = {
      id: Date.now(),
      type: 'user',
      content: input,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    
    // å‘é€åˆ°AI API
    const aiResponseContent = await sendToAI(input);
    
    const aiResponse: AIMessageData = {
      id: Date.now() + 1,
      type: 'ai',
      content: aiResponseContent,
      timestamp: new Date(),
      actions: getRelevantActions(input)
    };
    
    setMessages(prev => [...prev, aiResponse]);
  };

  // æ¨¡å‹é…ç½®ç›¸å…³å‡½æ•°
  const handleAddModel = () => {
    setEditingModel(null);
    setTempModelConfig({
      id: Date.now().toString(),
      name: '',
      provider: 'openai',
      apiUrl: '',
      apiKey: '',
      model: '',
      temperature: 0.7,
      maxTokens: 2048,
      systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº’åŠ¨å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ›å»ºç²¾å½©çš„AVGæ¸¸æˆå‰§æœ¬ã€‚'
    });
    setShowModelConfig(true);
  };

  const handleEditModel = (model: AIModelConfig) => {
    setEditingModel(model);
    setTempModelConfig({ ...model });
    setShowModelConfig(true);
  };

  const handleDeleteModel = (id: string) => {
    setModels(prev => prev.filter(m => m.id !== id));
    if (selectedModelId === id) {
      setSelectedModelId('');
    }
  };

  const handleSaveModel = () => {
    if (!tempModelConfig.name || !tempModelConfig.model || !tempModelConfig.apiUrl) {
      alert('è¯·å¡«å†™å¿…å¡«å­—æ®µ');
      return;
    }
    
    if (editingModel) {
      // æ›´æ–°ç°æœ‰æ¨¡å‹
      setModels(prev => prev.map(m => m.id === editingModel.id ? tempModelConfig : m));
    } else {
      // æ·»åŠ æ–°æ¨¡å‹
      setModels(prev => [...prev, tempModelConfig]);
    }
    
    setShowModelConfig(false);
  };

  const handleProviderChange = (providerId: AIModelConfig['provider']) => {
    setTempModelConfig(prev => {
      const provider = SUPPORTED_PROVIDERS.find(p => p.id === providerId);
      return {
        ...prev,
        provider: providerId,
        apiUrl: provider?.defaultApiUrl || ''
      };
    });
  };

  const getRelevantActions = (input: string): string[] => {
    if (input.includes('è§’è‰²')) return ['refine-character', 'add-dialogue', 'create-backstory'];
    if (input.includes('ä»£ç ')) return ['apply-fix', 'review-code', 'add-comments'];
    return ['continue-chat', 'generate-more', 'start-over'];
  };

  // ä¿å­˜æ¨¡å‹é…ç½®åˆ°localStorage
  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  if (!isOpen) return null;

  // ä¿å­˜é€‰ä¸­çš„æ¨¡å‹IDåˆ°localStorage
  useEffect(() => {
    if (selectedModelId) {
      localStorage.setItem('selected-ai-model', selectedModelId);
    }
  }, [selectedModelId]);

  if (!isOpen) return null;

  return (
    <div className="bg-gray-800 flex flex-col h-full w-full">
      {/* é¢æ¿å¤´éƒ¨ */}
      <div className="p-4 border-b border-gray-700 flex items-center justify-between">
        <div className="flex items-center space-x-3">
          <div className="relative">
            <Bot size={20} className="text-purple-400" />
            <div className="absolute -top-1 -right-1 w-3 h-3 bg-green-500 rounded-full border-2 border-gray-800" />
          </div>
          <div>
            <div className="font-semibold text-white">AI åˆ›ä½œåŠ©æ‰‹</div>
            <div className="text-xs text-gray-400">
              {getCurrentModel()?.name || 'æœªé€‰æ‹©æ¨¡å‹'} â€¢ åœ¨çº¿
            </div>
          </div>
        </div>
        <div className="flex items-center space-x-2">
          <button 
            onClick={() => setShowModelConfig(true)}
            className="text-gray-400 hover:text-white p-1 rounded"
          >
            <Settings size={16} />
          </button>
          <button 
            onClick={onToggle}
            className="text-gray-400 hover:text-white p-1 rounded"
          >
            <X size={16} />
          </button>
        </div>
      </div>

      {/* æ¨¡å‹é…ç½®é¢æ¿ */}
      {showModelConfig && (
        <div className="absolute inset-0 bg-gray-800 z-10 flex flex-col">
          <div className="p-4 border-b border-gray-700 flex items-center justify-between">
            <h3 className="font-semibold text-white">
              {editingModel ? 'ç¼–è¾‘æ¨¡å‹' : 'æ·»åŠ æ¨¡å‹'}
            </h3>
            <button 
              onClick={() => setShowModelConfig(false)}
              className="text-gray-400 hover:text-white p-1 rounded"
            >
              <X size={16} />
            </button>
          </div>
          
          <div className="flex-1 overflow-y-auto p-4 space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                æ¨¡å‹åç§° *
              </label>
              <input
                type="text"
                value={tempModelConfig.name}
                onChange={(e) => setTempModelConfig(prev => ({ ...prev, name: e.target.value }))}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                placeholder="ä¾‹å¦‚ï¼šGPT-4 Turbo"
              />
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                æœåŠ¡æä¾›å•† *
              </label>
              <select
                value={tempModelConfig.provider}
                onChange={(e) => handleProviderChange(e.target.value as AIModelConfig['provider'])}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
              >
                {SUPPORTED_PROVIDERS.map(provider => (
                  <option key={provider.id} value={provider.id}>
                    {provider.name}
                  </option>
                ))}
              </select>
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                API åœ°å€ *
              </label>
              <input
                type="text"
                value={tempModelConfig.apiUrl}
                onChange={(e) => setTempModelConfig(prev => ({ ...prev, apiUrl: e.target.value }))}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                placeholder={SUPPORTED_PROVIDERS.find(p => p.id === tempModelConfig.provider)?.defaultApiUrl || "https://api.example.com/v1/chat/completions"}
              />
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                API å¯†é’¥ *
              </label>
              <input
                type="password"
                value={tempModelConfig.apiKey}
                onChange={(e) => setTempModelConfig(prev => ({ ...prev, apiKey: e.target.value }))}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
              />
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                æ¨¡å‹åç§° *
              </label>
              <input
                type="text"
                value={tempModelConfig.model}
                onChange={(e) => setTempModelConfig(prev => ({ ...prev, model: e.target.value }))}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                placeholder="ä¾‹å¦‚ï¼šgpt-4-turbo"
              />
            </div>
            
            <div className="grid grid-cols-2 gap-4">
              <div>
                <label className="block text-sm font-medium text-gray-300 mb-1">
                  æ¸©åº¦ (0-2)
                </label>
                <input
                  type="number"
                  min="0"
                  max="2"
                  step="0.1"
                  value={tempModelConfig.temperature}
                  onChange={(e) => setTempModelConfig(prev => ({ ...prev, temperature: parseFloat(e.target.value) }))}
                  className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                />
              </div>
              
              <div>
                <label className="block text-sm font-medium text-gray-300 mb-1">
                  æœ€å¤§ Token
                </label>
                <input
                  type="number"
                  min="1"
                  value={tempModelConfig.maxTokens}
                  onChange={(e) => setTempModelConfig(prev => ({ ...prev, maxTokens: parseInt(e.target.value) }))}
                  className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                />
              </div>
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">
                ç³»ç»Ÿæç¤ºè¯
              </label>
              <div className="mb-2">
                <select
                  value={Object.keys(PRESET_SYSTEM_PROMPTS).find(key => 
                    PRESET_SYSTEM_PROMPTS[key as keyof typeof PRESET_SYSTEM_PROMPTS] === tempModelConfig.systemPrompt
                  ) || 'custom'}
                  onChange={(e) => {
                    if (e.target.value !== 'custom') {
                      setTempModelConfig(prev => ({
                        ...prev,
                        systemPrompt: PRESET_SYSTEM_PROMPTS[e.target.value as keyof typeof PRESET_SYSTEM_PROMPTS]
                      }));
                    }
                  }}
                  className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white mb-2"
                >
                  <option value="novelist">å°è¯´åˆ›ä½œä¸“å®¶</option>
                  <option value="coder">Inkè„šæœ¬ç¨‹åºå‘˜</option>
                  <option value="analyzer">å‰§æƒ…åˆ†æå¸ˆ</option>
                  <option value="teacher">åˆ›ä½œå¯¼å¸ˆ</option>
                  <option value="custom">è‡ªå®šä¹‰</option>
                </select>
              </div>
              <textarea
                value={tempModelConfig.systemPrompt}
                onChange={(e) => setTempModelConfig(prev => ({ ...prev, systemPrompt: e.target.value }))}
                className="w-full bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white"
                rows={6}
                placeholder="è¾“å…¥ç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡å¯¼AIçš„è¡Œä¸º..."
              />
              <p className="text-xs text-gray-400 mt-1">
                ç³»ç»Ÿæç¤ºè¯ç”¨äºæŒ‡å¯¼AIçš„è¡Œä¸ºå’Œå›ç­”é£æ ¼ã€‚é€‰æ‹©é¢„è®¾æ¨¡æ¿æˆ–è‡ªå®šä¹‰å†…å®¹ã€‚
              </p>
            </div>
          </div>
          
          <div className="p-4 border-t border-gray-700 flex justify-end space-x-2">
            <button
              onClick={() => setShowModelConfig(false)}
              className="px-4 py-2 text-gray-300 hover:text-white"
            >
              å–æ¶ˆ
            </button>
            <button
              onClick={handleSaveModel}
              className="px-4 py-2 bg-purple-600 text-white rounded hover:bg-purple-700"
            >
              ä¿å­˜
            </button>
          </div>
        </div>
      )}

      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <AIMessage key={message.id} message={message} />
        ))}
        
        {isAiThinking && <AIMessage message={{ id: 0, type: 'ai' as const, content: '', timestamp: new Date() }} />}
        <div ref={messagesEndRef} />
      </div>

      {/* å¿«æ·å»ºè®® */}
      <div className="px-4 py-2 border-t border-gray-700">
        <div className="text-xs text-gray-400 mb-2">å¿«æ·æé—®ï¼š</div>
        <div className="flex flex-wrap gap-2">
          {_suggestions.map((suggestion: string, index: number) => (
            <button
              key={index}
              onClick={() => setInput(suggestion)}
              className="text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded-full text-gray-300"
            >
              {suggestion}
            </button>
          ))}
        </div>
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="p-4 border-t border-gray-700">
        <div className="flex space-x-2 mb-3">
          <select
            value={selectedModelId}
            onChange={(e) => setSelectedModelId(e.target.value)}
            className="flex-1 bg-gray-700 border border-gray-600 rounded px-3 py-2 text-white text-sm"
          >
            <option value="">é€‰æ‹©æ¨¡å‹</option>
            {models.map(model => (
              <option key={model.id} value={model.id}>
                {model.name}
              </option>
            ))}
          </select>
          <button
            onClick={handleAddModel}
            className="p-2 bg-gray-700 text-gray-300 rounded hover:bg-gray-600"
            title="æ·»åŠ æ¨¡å‹"
          >
            <Plus size={16} />
          </button>
        </div>
        
        {models.length > 0 && selectedModelId && (
          <div className="mb-3 flex flex-wrap gap-2">
            {models
              .filter(model => model.id === selectedModelId)
              .map(model => (
                <div key={model.id} className="flex items-center bg-gray-700 rounded-full px-3 py-1 text-xs">
                  <span className="text-gray-300">{model.name}</span>
                  <button
                    onClick={() => handleEditModel(model)}
                    className="ml-2 text-gray-400 hover:text-white"
                  >
                    <Edit3 size={12} />
                  </button>
                  <button
                    onClick={() => handleDeleteModel(model.id)}
                    className="ml-1 text-gray-400 hover:text-red-400"
                  >
                    <Trash2 size={12} />
                  </button>
                </div>
              ))}
          </div>
        )}
        
        <div className="flex space-x-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
            placeholder="å‘AIåŠ©æ‰‹æé—®..."
            className="flex-1 bg-gray-700 rounded-lg px-3 py-2 text-sm border border-gray-600 focus:border-purple-500 focus:outline-none text-white placeholder-gray-400"
          />
          <button
            onClick={handleSendMessage}
            disabled={!input.trim() || isAiThinking || !selectedModelId}
            className="p-2 bg-purple-600 rounded-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <Send size={16} />
          </button>
        </div>
        
        <QuickActions onAction={(action) => {
          // æ ¹æ®æ“ä½œç±»å‹ç”Ÿæˆç›¸åº”çš„è¾“å…¥
          const actionPrompts: Record<string, string> = {
            'generate-character': 'å¸®æˆ‘åˆ›å»ºä¸€ä¸ªæ–°è§’è‰²ï¼ŒåŒ…æ‹¬å§“åã€èƒŒæ™¯æ•…äº‹å’Œæ€§æ ¼ç‰¹ç‚¹',
            'create-scene': 'å¸®æˆ‘è®¾è®¡ä¸€ä¸ªæ–°åœºæ™¯ï¼ŒåŒ…æ‹¬ç¯å¢ƒæè¿°å’Œå¯èƒ½çš„äº¤äº’å…ƒç´ ',
            'add-dialogue': 'ä¸ºå½“å‰åœºæ™¯ä¸­çš„è§’è‰²ç”Ÿæˆä¸€æ®µè‡ªç„¶çš„å¯¹è¯',
            'plot-twist': 'ä¸ºæˆ‘çš„æ•…äº‹è®¾è®¡ä¸€ä¸ªå‡ºäººæ„æ–™ä½†åˆç†çš„å‰§æƒ…è½¬æŠ˜',
            'fix-syntax': 'æ£€æŸ¥å¹¶ä¿®å¤æˆ‘æä¾›çš„Inkä»£ç ä¸­çš„è¯­æ³•é”™è¯¯',
            'optimize-code': 'ä¼˜åŒ–è¿™æ®µInkä»£ç çš„ç»“æ„å’Œå¯è¯»æ€§',
            'add-variables': 'æ ¹æ®æˆ‘çš„å‰§æƒ…éœ€è¦ï¼Œå»ºè®®ä¸€äº›æœ‰ç”¨çš„å˜é‡æ¥è·Ÿè¸ªçŠ¶æ€',
            'format-code': 'é‡æ–°æ ¼å¼åŒ–è¿™æ®µInkä»£ç ï¼Œä½¿å…¶æ›´æ˜“è¯»',
            'analyze-flow': 'åˆ†ææˆ‘çš„å‰§æƒ…åˆ†æ”¯é€»è¾‘ï¼ŒæŒ‡å‡ºå¯èƒ½çš„é—®é¢˜',
            'check-balance': 'è¯„ä¼°æˆ‘çš„æ¸¸æˆé€‰é¡¹æ˜¯å¦å¹³è¡¡ï¼Œæ˜¯å¦å­˜åœ¨è¿‡äºç®€å•æˆ–å›°éš¾çš„éƒ¨åˆ†',
            'review-story': 'å…¨é¢è¯„ä¼°æˆ‘çš„æ•…äº‹ï¼ŒåŒ…æ‹¬è§’è‰²ã€æƒ…èŠ‚ã€å¯¹è¯ç­‰æ–¹é¢',
            'suggest-improve': 'åŸºäºå½“å‰å†…å®¹ï¼Œæä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®'
          };
          
          const prompt = actionPrompts[action] || 'è¯·æä¾›æ›´å¤šå¸®åŠ©';
          setInput(prompt);
        }} />
      </div>
    </div>
  );
};

export default AIChatPanel;